{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextGeneration-109403021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKPksUD96Mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf5118b-1a62-44b9-ce7c-3021b3943e5c"
      },
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "# 太多人同時存取可能會報cannot retrieve file error\n",
        "# 點擊you may still be able to access 下面那個連結再自行上傳檔案即可\n",
        "\n",
        "!gdown --id 1E4YxLlApsfwOpTjxBvf9C2sYbcGG7oVx --output \"./金庸《笑傲江湖》.txt\"\n",
        "\n",
        "# !wget -O Eileen_Legendary.txt \"http://140.115.82.54/NN/Recurrent/Eileen_Legendary.txt\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1E4YxLlApsfwOpTjxBvf9C2sYbcGG7oVx\n",
            "To: /content/金庸《笑傲江湖》.txt\n",
            "100% 2.95M/2.95M [00:00<00:00, 248MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mbvzh_9_Tz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48055c2-8f32-4251-8015-556a763a221a"
      },
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"./金庸《笑傲江湖》.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"金庸《笑傲江湖》共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "金庸《笑傲江湖》共有 989231 字詞\n",
            "包含了 3932 個獨一無二的字 (含標點符號)\n",
            "\n",
            "\n",
            "《二○一五年十一月六日版》\n",
            "《好讀書櫃》典藏版\n",
            "第一章 滅門\n",
            "和風薰柳，花香醉人，正是南國春光漫爛季節。\n",
            "福建省福州府西門大街，青石板路筆直的伸展出去，直通西門。一座建構宏偉的宅第之前，左右兩座石壇中各豎一根兩丈來高的旗桿，桿頂飄揚青旗。右首旗上黃色絲線繡著一頭張牙舞爪、神態威猛的雄獅，旗子隨風招展，顯得雄獅更奕奕若生。雄獅頭頂有一對黑絲線繡的蝙蝠展翅飛翔。左首旗上繡著「福威鏢局」四個黑字，銀鉤鐵劃，剛勁非凡。\n",
            "大宅朱漆大門，門上茶杯大小的銅釘閃閃發光，門頂匾額寫著「福威鏢局」四個金漆大字，下面橫書「總號」兩個小字。進門處兩排長櫈，分坐著八名勁裝結束的漢子，個個腰板筆挺，顯出一股英悍之氣。\n",
            "突然間後院馬蹄聲響，那八名漢子一齊站起，搶出大門。只見鏢局西側門中衝出五騎馬來，沿著馬道衝到大門之前。當先一匹馬全身雪白，馬勒腳鐙都是爛銀打就，鞍上一個錦衣少年，約莫十八九歲年紀，左肩上停著一頭獵鷹，腰懸寶劍，背負長弓，潑喇喇縱馬疾馳。身後跟隨四騎，騎者一色青布短衣。\n",
            "一行五人馳到鏢局門口，八名漢子中有三個齊聲叫了起來：「少鏢頭又打獵去啦！」那少年哈哈一笑，馬鞭在空中拍的一響，虛擊聲下，胯下白馬昂\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "3e2d3098-d0e3-4e2c-d6bd-9d20696f28ca"
      },
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 2603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "87f226af-1074-4b1e-f11c-06cfb90a1b96"
      },
      "source": [
        "print(f\"原本金庸《笑傲江湖》共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本金庸《笑傲江湖》共有 989231 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘984914個字\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "136c5939-27ed-41d9-acc4-b3e431032267"
      },
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['\\n', '二', '一', '五', '年', '十', '一', '月', '六', '日', '\\n', '好', '讀', '書', '櫃', '典', '藏', '\\n', '第', '一', '章', '滅', '門', '\\n', '和', '風', '柳', '，', '花', '香', '醉', '人', '，', '正', '是', '南', '國', '春', '光', '漫']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{647, 2452, 2295, 2205, 2590, 2591, 2593, 675, 2599, 2602, 2477, 2482, 2486, 2488, 2232, 2495, 1601, 1475, 197, 844, 1879, 1495, 2532, 1766, 2537, 2284, 2417, 1267, 1654, 2551, 504, 2425, 1274, 2431}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "7b1c8e72-07b8-4f3a-fc67-d33d23ec2a3e"
      },
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[2590 2486 2599 2452 2431 2495 2599 2205 2417 2488 2590 2551 1267 1879\n",
            "  197 1601 1766 2590 2295 2599  504], shape=(21,), dtype=int32)\n",
            "['\\n', '二', '一', '五', '年', '十', '一', '月', '六', '日', '\\n', '好', '讀', '書', '櫃', '典', '藏', '\\n', '第', '一', '章']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[1475 2532 2590 2537 2425  844 2602 2284 1654 1274 2591 2602 2477 2593\n",
            " 2232 1495  647 2482  675 1550  252], shape=(21,), dtype=int32)\n",
            "['滅', '門', '\\n', '和', '風', '柳', '，', '花', '香', '醉', '人', '，', '正', '是', '南', '國', '春', '光', '漫', '爛', '季']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "6a7ba4c7-8da6-4a8f-b21a-bbc440d823f5"
      },
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "937243f8-257b-428d-8157-f6541a055fd5"
      },
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['\\n', '二', '一', '五', '年', '十', '一', '月', '六', '日', '\\n', '好', '讀', '書', '櫃', '典', '藏', '\\n', '第', '一']\n",
            "Target: ['二', '一', '五', '年', '十', '一', '月', '六', '日', '\\n', '好', '讀', '書', '櫃', '典', '藏', '\\n', '第', '一', '章']\n",
            "--------------------------------------------------\n",
            "Input : [2590 2486 2599 2452 2431 2495 2599 2205 2417 2488 2590 2551 1267 1879\n",
            "  197 1601 1766 2590 2295 2599]\n",
            "Target: [2486 2599 2452 2431 2495 2599 2205 2417 2488 2590 2551 1267 1879  197\n",
            " 1601 1766 2590 2295 2599  504]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "d27f7b0d-0666-4bc6-a0c1-054c47eec1d6"
      },
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "7685a4ec-077a-441b-c5ed-75f93cad47ca"
      },
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 512)         1332736   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 2603)        5333547   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,519,979\n",
            "Trainable params: 132,519,979\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "92f6bd08-c8d0-4b8d-cc4b-b457e1bdcd60"
      },
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 2603)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "61fd3101-a7aa-4eb7-f129-d6794ada58b2"
      },
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "搶著將眾人如何議論劉正風金盆洗手、莫大先\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "插呻呻鬼鬼鬼鬼漲漲袱赤赤衡衡衡衡衡談顆顆\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPfQAQBonFj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "21e55f4a-463f-42a1-93a8-24cd377b7f8c"
      },
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "732/732 [==============================] - 290s 391ms/step - loss: 5.1959\n",
            "Epoch 2/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 4.1910\n",
            "Epoch 3/20\n",
            "732/732 [==============================] - 291s 397ms/step - loss: 3.7916\n",
            "Epoch 4/20\n",
            "732/732 [==============================] - 292s 399ms/step - loss: 3.5141\n",
            "Epoch 5/20\n",
            "732/732 [==============================] - 292s 399ms/step - loss: 3.2723\n",
            "Epoch 6/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 3.0302\n",
            "Epoch 7/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 2.7731\n",
            "Epoch 8/20\n",
            "732/732 [==============================] - 291s 398ms/step - loss: 2.4907\n",
            "Epoch 9/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 2.1833\n",
            "Epoch 10/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 1.8560\n",
            "Epoch 11/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 1.5253\n",
            "Epoch 12/20\n",
            "732/732 [==============================] - 292s 399ms/step - loss: 1.2113\n",
            "Epoch 13/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 0.9360\n",
            "Epoch 14/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 0.7233\n",
            "Epoch 15/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 0.5789\n",
            "Epoch 16/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 0.4950\n",
            "Epoch 17/20\n",
            "732/732 [==============================] - 292s 398ms/step - loss: 0.4514\n",
            "Epoch 18/20\n",
            "732/732 [==============================] - 291s 397ms/step - loss: 0.4281\n",
            "Epoch 19/20\n",
            "732/732 [==============================] - 291s 397ms/step - loss: 0.4138\n",
            "Epoch 20/20\n",
            "732/732 [==============================] - 291s 397ms/step - loss: 0.4030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbK80fXpOWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "afd46147-f6cb-421d-9648-a43c0fe5ced5"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "ef83a22f-556d-4389-c7be-e032e8de0495"
      },
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "搶著將眾人如何議論劉正風金盆洗手、莫大先\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "劫將眾人如何議論劉正風金盆洗手、莫大先生\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ELuAjW3rKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8345a9-d0f9-48b8-9f87-1ec617c6352a"
      },
      "source": [
        "init_seq = \"任盈盈\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,500)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "任盈盈死了，你怎地如此胡塗？」岳靈珊道：「我……我怎能是除了辟邪劍譜？」林平之道：「我怎知道？」林平之道：「我在恆山上出手，你殺我而已。」\n",
            "令狐冲「嗯」了一聲，心想：「原來是一個小小婆娘打扮的，有甚麼不好？」岳靈珊道：「是，是。」林平之道：「不錯，我自宮之後，仍和你師娘人數雖大，說過的話，卻和田伯光一定喜歡了喉嚨，便要走上山去。」\n",
            "令狐冲和盈盈又感欣點嘴角，不知去向。\n",
            "\n",
            "\n",
            "令狐冲和盈盈交個朋友求死，大家分明以後，必定要一場不勝。」說著挺劍直向他左肩。令狐冲見過要倒地的好看，已然熟了，也沒加傷的傷口，便道：「好，我送你去見師娘。」\n",
            "令狐冲默然不語。\n",
            "這日令狐冲已經得過今日，他一直要自己拿了去，自己自然只有自殺盈盈，隨即也切他不得其事，心下也就不想，但從前十餘人也是十分聰明機境，其實本事雖在頗深，心想：「這位佛門高僧不通世務，當真得深自可。」\n",
            "耳聽得定靜師太從南安客店中出來。\n",
            "※※※\n",
            "令狐冲躬身從馬匹走了開去，一張椅便給噴了出去。\n",
            "令狐冲忽覺右臂上劇痛，右臂小腹中登時露出了一隻青布長袍，只嚇得手中發出半截聲音，跟著砰拍之聲大作。\n",
            "令狐冲心想：「青城派那姓余的小子無冤無仇，為甚麼要拘留任小姐？你是"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdT8wg_P6CtF"
      },
      "source": [
        "# 不要執行這一個block\n",
        "import time\n",
        "while True:\n",
        "  time.sleep(5)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erwsMKL08Ql9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}